name: Deploy to GKE with Monitoring
on:
  push:
    branches:
      - main  # Deploy on push to main
  workflow_dispatch: # Allows manual trigger
jobs:
  deploy:
    runs-on: self-hosted  # Use your self-hosted runner
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4  # Clones repo to the runner
      
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}
      
      - name: Set up gcloud CLI
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: canvas-spark-446913-b1
          export_default_credentials: true
      
      - name: Set up kubectl
        run: |
          gcloud container clusters get-credentials my-gke-cluster --region us-central1-a --project canvas-spark-446913-b1
          kubectl version --client
      
      - name: Deploy Manifests to GKE
        run: |
          kubectl apply -f manifest_files/postgres.yaml
          kubectl apply -f manifest_files/backend.yaml
          kubectl apply -f manifest_files/frontend.yaml
      
      - name: Install Helm
        run: |
          curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
          helm version
      
      - name: Add Prometheus and Grafana Helm repositories
        run: |
          helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
          helm repo add grafana https://grafana.github.io/helm-charts
          helm repo update
      
      - name: Create monitoring namespace
        run: |
          kubectl create namespace monitoring --dry-run=client -o yaml | kubectl apply -f -
      
      # Use an older version of Prometheus Operator CRDs with smaller annotations
      - name: Install Prometheus Operator CRDs from older version
        run: |
          # Use a specific older version (v0.48.0) that has smaller annotations
          kubectl apply -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.48.0/example/prometheus-operator-crd/monitoring.coreos.com_servicemonitors.yaml
          kubectl apply -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.48.0/example/prometheus-operator-crd/monitoring.coreos.com_podmonitors.yaml
          kubectl apply -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.48.0/example/prometheus-operator-crd/monitoring.coreos.com_prometheuses.yaml
          kubectl apply -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.48.0/example/prometheus-operator-crd/monitoring.coreos.com_alertmanagers.yaml
          kubectl apply -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.48.0/example/prometheus-operator-crd/monitoring.coreos.com_prometheusrules.yaml
          
          # Wait for CRDs to be established
          echo "Waiting for ServiceMonitor CRD to be established..."
          kubectl wait --for condition=established --timeout=60s crd/servicemonitors.monitoring.coreos.com
      
      # Use Google Container Registry mirrors instead of Quay.io
      - name: Deploy Prometheus
        run: |
          helm upgrade --install prometheus prometheus-community/prometheus \
            --namespace monitoring \
            --set server.persistentVolume.enabled=true \
            --set server.persistentVolume.size=10Gi \
            --set server.image.repository=gcr.io/google-samples/prometheus \
            --set server.image.tag=v2.40.7 \
            --set alertmanager.image.repository=gcr.io/google-samples/alertmanager \
            --set alertmanager.image.tag=v0.24.0 \
            --set pushgateway.image.repository=gcr.io/google-samples/pushgateway \
            --set pushgateway.image.tag=v1.4.3
      
      # Check existing Grafana PVC before deployment
      - name: Check existing Grafana PVC
        run: |
          if kubectl get pvc -n monitoring grafana 2>/dev/null; then
            echo "Current PVC size:"
            kubectl get pvc -n monitoring grafana -o jsonpath='{.spec.resources.requests.storage}'
            echo
          else
            echo "No existing PVC found"
          fi
      
      - name: Deploy Grafana
        run: |
          helm upgrade --install grafana grafana/grafana \
            --namespace monitoring \
            --set persistence.enabled=true \
            --set persistence.size=10Gi \
            --set service.type=LoadBalancer \
            --set image.repository=docker.io/grafana/grafana \
            --set image.tag=9.5.2 \
            --values - <<EOF
          datasources:
            datasources.yaml:
              apiVersion: 1
              datasources:
              - name: Prometheus
                type: prometheus
                url: http://prometheus-server.monitoring.svc.cluster.local
                access: proxy
                isDefault: true
          EOF
      
      - name: Deploy node-exporter as DaemonSet
        run: |
          cat <<EOF | kubectl apply -f -
          apiVersion: apps/v1
          kind: DaemonSet
          metadata:
            name: node-exporter
            namespace: monitoring
            labels:
              app: node-exporter
          spec:
            selector:
              matchLabels:
                app: node-exporter
            template:
              metadata:
                labels:
                  app: node-exporter
              spec:
                containers:
                - name: node-exporter
                  image: docker.io/prom/node-exporter:v1.5.0
                  ports:
                  - containerPort: 9100
                    name: metrics
                  volumeMounts:
                  - name: proc
                    mountPath: /host/proc
                    readOnly: true
                  - name: sys
                    mountPath: /host/sys
                    readOnly: true
                volumes:
                - name: proc
                  hostPath:
                    path: /proc
                - name: sys
                  hostPath:
                    path: /sys
          ---
          apiVersion: v1
          kind: Service
          metadata:
            name: node-exporter
            namespace: monitoring
            labels:
              app: node-exporter
          spec:
            ports:
            - port: 9100
              targetPort: 9100
              name: metrics
            selector:
              app: node-exporter
          EOF
      
      - name: Deploy ServiceMonitors for your applications
        run: |
          cat <<EOF | kubectl apply -f -
          apiVersion: monitoring.coreos.com/v1
          kind: ServiceMonitor
          metadata:
            name: backend-monitor
            namespace: monitoring
          spec:
            selector:
              matchLabels:
                app: backend  # match your backend service labels
            endpoints:
            - port: metrics   # the port your app exposes Prometheus metrics on
              interval: 15s
          ---
          apiVersion: monitoring.coreos.com/v1
          kind: ServiceMonitor
          metadata:
            name: frontend-monitor
            namespace: monitoring
          spec:
            selector:
              matchLabels:
                app: frontend  # match your frontend service labels
            endpoints:
            - port: metrics    # the port your app exposes Prometheus metrics on
              interval: 15s
          EOF
      
      - name: Create Prometheus scrape configs for node-exporter
        run: |
          cat <<EOF | kubectl apply -f -
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: prometheus-server-conf
            namespace: monitoring
            labels:
              app: prometheus
          data:
            prometheus.yml: |
              global:
                scrape_interval: 15s
              scrape_configs:
                - job_name: 'node-exporter'
                  kubernetes_sd_configs:
                    - role: endpoints
                      namespaces:
                        names:
                          - monitoring
                  relabel_configs:
                    - source_labels: [__meta_kubernetes_service_name]
                      regex: node-exporter
                      action: keep
                - job_name: 'kubernetes-pods'
                  kubernetes_sd_configs:
                    - role: pod
                  relabel_configs:
                    - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
                      action: keep
                      regex: true
                    - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
                      action: replace
                      target_label: __metrics_path__
                      regex: (.+)
                    - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
                      action: replace
                      regex: ([^:]+)(?::\d+)?;(\d+)
                      replacement: $1:$2
                      target_label: __address__
                    - action: labelmap
                      regex: __meta_kubernetes_pod_label_(.+)
                    - source_labels: [__meta_kubernetes_namespace]
                      action: replace
                      target_label: kubernetes_namespace
                    - source_labels: [__meta_kubernetes_pod_name]
                      action: replace
                      target_label: kubernetes_pod_name
                - job_name: 'kubernetes-services'
                  kubernetes_sd_configs:
                    - role: service
                  relabel_configs:
                    - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
                      action: keep
                      regex: true
                    - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
                      action: replace
                      target_label: __metrics_path__
                      regex: (.+)
                    - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
                      action: replace
                      regex: ([^:]+)(?::\d+)?;(\d+)
                      replacement: $1:$2
                      target_label: __address__
                    - action: labelmap
                      regex: __meta_kubernetes_service_label_(.+)
                    - source_labels: [__meta_kubernetes_namespace]
                      action: replace
                      target_label: kubernetes_namespace
                    - source_labels: [__meta_kubernetes_service_name]
                      action: replace
                      target_label: kubernetes_service_name
          EOF
          
          # Apply the ConfigMap to Prometheus
          kubectl -n monitoring patch deployment prometheus-server -p '{"spec":{"template":{"spec":{"volumes":[{"name":"config-volume","configMap":{"name":"prometheus-server-conf"}}]}}}}'
      
      - name: Import Dashboards to Grafana
        run: |
          cat <<EOF | kubectl apply -f -
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: grafana-dashboards
            namespace: monitoring
            labels:
              grafana_dashboard: "1"
          data:
            kubernetes-pod-overview.json: |
              {
                "annotations": {
                  "list": []
                },
                "editable": true,
                "gnetId": null,
                "graphTooltip": 0,
                "id": null,
                "links": [],
                "panels": [
                  {
                    "datasource": "Prometheus",
                    "fieldConfig": {
                      "defaults": {
                        "color": {
                          "mode": "palette-classic"
                        },
                        "custom": {
                          "axisLabel": "",
                          "axisPlacement": "auto",
                          "barAlignment": 0,
                          "drawStyle": "line",
                          "fillOpacity": 10,
                          "gradientMode": "none",
                          "hideFrom": {
                            "legend": false,
                            "tooltip": false,
                            "viz": false
                          },
                          "lineInterpolation": "linear",
                          "lineWidth": 1,
                          "pointSize": 5,
                          "scaleDistribution": {
                            "type": "linear"
                          },
                          "showPoints": "never",
                          "spanNulls": true
                        },
                        "mappings": [],
                        "thresholds": {
                          "mode": "absolute",
                          "steps": [
                            {
                              "color": "green",
                              "value": null
                            }
                          ]
                        },
                        "unit": "percentunit"
                      },
                      "overrides": []
                    },
                    "gridPos": {
                      "h": 8,
                      "w": 12,
                      "x": 0,
                      "y": 0
                    },
                    "id": 2,
                    "options": {
                      "legend": {
                        "calcs": [],
                        "displayMode": "list",
                        "placement": "bottom"
                      },
                      "tooltip": {
                        "mode": "single"
                      }
                    },
                    "targets": [
                      {
                        "expr": "sum(rate(container_cpu_usage_seconds_total{container!=\"\"}[5m])) by (pod)",
                        "interval": "",
                        "legendFormat": "{{pod}}",
                        "refId": "A"
                      }
                    ],
                    "title": "Pod CPU Usage",
                    "type": "timeseries"
                  },
                  {
                    "datasource": "Prometheus",
                    "fieldConfig": {
                      "defaults": {
                        "color": {
                          "mode": "palette-classic"
                        },
                        "custom": {
                          "axisLabel": "",
                          "axisPlacement": "auto",
                          "barAlignment": 0,
                          "drawStyle": "line",
                          "fillOpacity": 10,
                          "gradientMode": "none",
                          "hideFrom": {
                            "legend": false,
                            "tooltip": false,
                            "viz": false
                          },
                          "lineInterpolation": "linear",
                          "lineWidth": 1,
                          "pointSize": 5,
                          "scaleDistribution": {
                            "type": "linear"
                          },
                          "showPoints": "never",
                          "spanNulls": true
                        },
                        "mappings": [],
                        "thresholds": {
                          "mode": "absolute",
                          "steps": [
                            {
                              "color": "green",
                              "value": null
                            }
                          ]
                        },
                        "unit": "bytes"
                      },
                      "overrides": []
                    },
                    "gridPos": {
                      "h": 8,
                      "w": 12,
                      "x": 12,
                      "y": 0
                    },
                    "id": 3,
                    "options": {
                      "legend": {
                        "calcs": [],
                        "displayMode": "list",
                        "placement": "bottom"
                      },
                      "tooltip": {
                        "mode": "single"
                      }
                    },
                    "targets": [
                      {
                        "expr": "sum(container_memory_usage_bytes{container!=\"\"}) by (pod)",
                        "interval": "",
                        "legendFormat": "{{pod}}",
                        "refId": "A"
                      }
                    ],
                    "title": "Pod Memory Usage",
                    "type": "timeseries"
                  }
                ],
                "refresh": "10s",
                "schemaVersion": 30,
                "style": "dark",
                "tags": [],
                "templating": {
                  "list": []
                },
                "time": {
                  "from": "now-1h",
                  "to": "now"
                },
                "timepicker": {},
                "timezone": "",
                "title": "Kubernetes Pod Overview",
                "uid": "k8s-pod-overview",
                "version": 1
              }
          EOF
      
      - name: Get Grafana admin password
        run: |
          echo "Grafana admin password:"
          kubectl get secret --namespace monitoring grafana -o jsonpath="{.data.admin-password}" | base64 --decode; echo
      
      - name: Verify Monitoring Deployment
        run: |
          echo "Checking Prometheus components:"
          kubectl get pods -n monitoring
          echo "Checking services:"
          kubectl get svc -n monitoring
          echo "Grafana will be available at the LoadBalancer IP below:"
          kubectl get svc grafana -n monitoring
      
      # Optional: Add fallback step if PVC issue persists
      - name: Fallback - Delete and recreate Grafana PVC (Only if needed)
        if: ${{ failure() }}
        run: |
          echo "Previous steps failed, attempting fallback procedure..."
          echo "WARNING: This will delete Grafana data. Starting backup process..."
          
          # Try to export Grafana dashboards before deletion if possible
          kubectl -n monitoring exec -it $(kubectl -n monitoring get pods -l "app.kubernetes.io/name=grafana" -o jsonpath="{.items[0].metadata.name}") -- \
            bash -c "apt-get update && apt-get install -y curl jq && \
            token=\$(curl -s -X POST -H 'Content-Type: application/json' -d '{\"name\":\"backup\",\"role\":\"Admin\"}' \
            http://admin:\$(cat /etc/grafana/admin-password)@localhost:3000/api/auth/keys | jq -r '.key') && \
            mkdir -p /tmp/dashboards && \
            for uid in \$(curl -s -H \"Authorization: Bearer \$token\" http://localhost:3000/api/search?type=dash-db | jq -r '.[].uid'); do \
              curl -s -H \"Authorization: Bearer \$token\" http://localhost:3000/api/dashboards/uid/\$uid > /tmp/dashboards/\$uid.json; \
            done" || echo "Failed to backup dashboards, proceeding with deletion"
          
          # Delete Grafana resources
          helm uninstall grafana -n monitoring
          kubectl delete pvc -n monitoring grafana
          
          # Reinstall with correct size
          helm upgrade --install grafana grafana/grafana \
            --namespace monitoring \
            --set persistence.enabled=true \
            --set persistence.size=10Gi \
            --set service.type=LoadBalancer \
            --set image.repository=docker.io/grafana/grafana \
            --set image.tag=9.5.2 \
            --values - <<EOF
          datasources:
            datasources.yaml:
              apiVersion: 1
              datasources:
              - name: Prometheus
                type: prometheus
                url: http://prometheus-server.monitoring.svc.cluster.local
                access: proxy
                isDefault: true
          EOF
          
          echo "Grafana reinstalled. Note: Previous dashboards will need to be reimported."
